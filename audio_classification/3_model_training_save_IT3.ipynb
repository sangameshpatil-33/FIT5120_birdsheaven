{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77043726",
   "metadata": {},
   "source": [
    "### IMPORT ALL REQUIRED LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5639de72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten,Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69102c58",
   "metadata": {},
   "source": [
    "### READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5783621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file to a dataframe format\n",
    "extracted_features_df = pd.read_csv('feature_vector_specie_df.csv')\n",
    "# display top 5 rows of the dataframe\n",
    "extracted_features_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28ff86c",
   "metadata": {},
   "source": [
    "### CLEAN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f9a09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the first value of the feature column of the dataframe\n",
    "extracted_features_df.feature[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81fffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the format of the values in feature column \n",
    "extracted_features_df.feature[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb01c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the dataframe\n",
    "for i in range(len(extracted_features_df)):\n",
    "    # strip the characters that are not required\n",
    "    extracted_features_df.feature[i] = extracted_features_df.feature[i].strip('[')\n",
    "    extracted_features_df.feature[i] = extracted_features_df.feature[i].strip(']')\n",
    "    extracted_features_df.feature[i] = extracted_features_df.feature[i].strip('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30add94",
   "metadata": {},
   "outputs": [],
   "source": [
    "float(extracted_features_df.feature[2].split(\",\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d20b7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the features imported in the file were in string format, we clean and wrangle it to a list format \n",
    "\n",
    "# create empty string to store the features\n",
    "features = []\n",
    "# iterate through the feature column to the dataframe\n",
    "for i in extracted_features_df.feature:\n",
    "    # split the data where \",\" found\n",
    "    m = i.split(\",\")\n",
    "    # create empty list to store the values\n",
    "    lst =[]\n",
    "    # iterate through each value of th elist after the split\n",
    "    for j in m:\n",
    "        # store the values in float format \n",
    "        lst.append(float(j))\n",
    "    # print the values\n",
    "    print(lst)\n",
    "    # append values to the main feature list\n",
    "    features.append(lst)\n",
    "        \n",
    "# store the cleaned required format in the dataframe\n",
    "extracted_features_df.feature = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d8d91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print and check if the data is as per the requirement\n",
    "extracted_features_df['feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74061e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stoer the input variables as a list\n",
    "X=np.array(extracted_features_df['feature'].tolist())\n",
    "# stoer the target variable as a list\n",
    "y=np.array(extracted_features_df['specie'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe63c5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function label encoder\n",
    "labelencoder=LabelEncoder()\n",
    "# conver the target variable column to categorical format\n",
    "y= to_categorical(labelencoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15721bb0",
   "metadata": {},
   "source": [
    "### SPLIT DATA TO TRAIN AND TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a05c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the values of input variable list and target variable list, split the data into 75% as train and 25% as test data\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=3, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a13d505",
   "metadata": {},
   "source": [
    "### BUILD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da912202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the number of categories of the target variable\n",
    "num_labels=5\n",
    "\n",
    "# call the deep learning model : Sequencial\n",
    "model=Sequential()\n",
    "# first layer\n",
    "model.add(Dense(100,input_shape=(40,)))\n",
    "# add activation layer \"relu\"\n",
    "model.add(Activation('relu'))\n",
    "# add dropout to the model\n",
    "model.add(Dropout(0.4))\n",
    "# final layer\n",
    "model.add(Dense(num_labels))\n",
    "# add activation layer \"softmax\" to convert vectors into probabilities\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f17884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model using the loss function cross entropy\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d59158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80239a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the number of epochs\n",
    "num_epochs = 50\n",
    "# define batch size for each epoch\n",
    "num_batch_size = 256\n",
    "\n",
    "# create a checkpointer to save the best model\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.sequential.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "# fit the model using the training values and the defined parameters. Validate the model on the testing data\n",
    "history = model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, callbacks=[checkpointer], validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed7bf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the values of the model fitting\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f57547e",
   "metadata": {},
   "source": [
    "### VISUALISE MODEL FITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b506de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy of the model\n",
    "plt.plot(history.history['accuracy'])\n",
    "# plot validation accuracy of the model\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "# define title of the plot\n",
    "plt.title('model accuracy')\n",
    "# define the label of y-axis\n",
    "plt.ylabel('accuracy')\n",
    "# define the label of x-axis\n",
    "plt.xlabel('epoch')\n",
    "# define the legend and its position\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "# show the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eb7006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss of the model\n",
    "plt.plot(history.history['loss'])\n",
    "# plot validation loss of the model\n",
    "plt.plot(history.history['val_loss'])\n",
    "# define title of the plot\n",
    "plt.title('model loss')\n",
    "# define the label of y-axis\n",
    "plt.ylabel('loss')\n",
    "# define the label of x-axis\n",
    "plt.xlabel('epoch')\n",
    "# define the legend and its position\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "# show the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b441a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7f4465",
   "metadata": {},
   "source": [
    "### OUTPUTS OF VARIOUS TRIAL METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0b9f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with different melbourne ksyline birds as seperate categories + balanced sampling \n",
    "# Training Accuracy:  0.4318658411502838\n",
    "# Testing Accuracy:  0.28125\n",
    "  \n",
    "# with different skyline birds as seperate categories + oversampling only\n",
    "# Training Accuracy:  0.4118658411502838\n",
    "# Testing Accuracy:  0.30125\n",
    "    \n",
    "# with different skyline birds as one category + oversampling only\n",
    "# Training Accuracy:  0.8696969747543335\n",
    "# Testing Accuracy:  0.8060606122016907\n",
    "\n",
    "# with different skyline birds as one category + category of not birds category + oversampling only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c87d957",
   "metadata": {},
   "source": [
    "### TESTING DATA WITH A NEW TEST FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0510bffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa\n",
    "# import numpy as np\n",
    "\n",
    "# filename = \"C:\\\\Users\\\\pragya\\\\Downloads\\\\1334324461.wav\"\n",
    "# audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
    "# mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "# mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "\n",
    "# print(mfccs_scaled_features, '\\n')\n",
    "# mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
    "# print(mfccs_scaled_features, '\\n')\n",
    "# print(mfccs_scaled_features.shape, '\\n')\n",
    "# predicted_label=model.predict(mfccs_scaled_features)\n",
    "# print(predicted_label, '\\n')\n",
    "# classes_x=np.argmax(predicted_label,axis=1)\n",
    "# print(classes_x, '\\n')\n",
    "# prediction_class = labelencoder.inverse_transform(classes_x)\n",
    "# prediction_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cff6fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### check the encodes for each category of the target variable\n",
    "# labelencoder.inverse_transform([0])\n",
    "# labelencoder.inverse_transform([1])\n",
    "# labelencoder.inverse_transform([2])\n",
    "# labelencoder.inverse_transform([3])\n",
    "# labelencoder.inverse_transform([4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
